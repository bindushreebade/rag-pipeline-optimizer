ğŸ“˜ RAG Pipeline Optimizer (Groq + Streamlit + FAISS + LangChain)

A multi-pipeline Retrieval-Augmented Generation system with automated LLM-based evaluation.

ğŸš€ Overview

The RAG Pipeline Optimizer is an intelligent system that evaluates multiple RAG pipelines in parallel to determine which retrieval strategy produces the best answer for any question.

It uses:

Groq LLaMA models for ultra-fast inference

FAISS and Chroma for vector retrieval

Sentence-Transformers for embeddings

Streamlit for a beautiful UI

LLM-as-a-Judge to automatically select the best pipeline

This tool is perfect for:

Researching RAG configurations

Comparing chunk sizes, models, and retrieval strategies

Understanding which pipeline gives the most accurate answer

Building your own advanced retrieval benchmarks

ğŸ¯ Features
âœ” Multi-Pipeline Retrieval

Runs 4 different RAG pipelines (A, B, C, D) with:

Different chunk sizes

Different retrieval depths

Optional reranking

Different LLM models

âœ” Automated Pipeline Evaluation

A separate Groq model analyzes all four answers and chooses:

ğŸ† Best Pipeline: A/B/C/D

This turns your project into a real RAG research tool.

âœ” Document Ingestion Pipeline

Upload a PDF â†’ Split â†’ Embed â†’ Build FAISS vectorstore.

Each pipeline uses its own vectorstore for experimentation.

âœ” Instant UI (Streamlit)

Includes:

Input question box

Beautiful 4-column comparison grid

Expandable retrieved documents viewer

Highlighted "Best Pipeline" badge

ğŸ§  Architecture
PDF â†’ Ingestion â†’ FAISS Vectorstores â†’ 4 Pipelines â†’ Groq LLM â†’ Judge Model â†’ Streamlit UI

ğŸ“ Project Structure
rag_pipeline_optimizer/
â”‚
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ ingest.py
â”‚   â”‚   â”œâ”€â”€ pipelines.py
â”‚   â”‚   â”œâ”€â”€ retrievers.py
â”‚   â”‚   â”œâ”€â”€ config.py
â”‚   â”‚   â”œâ”€â”€ server.py
â”‚   â”‚   â””â”€â”€ data/vectorstores/
â”‚   â”œâ”€â”€ venv/
â”‚   â””â”€â”€ requirements.txt
â”‚
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ app.py   â† Streamlit UI
â”‚
â””â”€â”€ README.md

ğŸ›  Installation Guide
ğŸ“Œ Requirements
Component	Version
Python	3.10.x (recommended)
pip	latest
Groq SDK	0.12+
FAISS CPU	1.8.0
Streamlit	1.40+
ğŸ“¥ Step 1 â€” Clone the repo
git clone https://github.com/bindushreebade/rag-pipeline-optimizer.git
cd rag-pipeline-optimizer

ğŸ“¥ Step 2 â€” Create Backend Virtual Environment
cd backend
python -m venv venv
venv\Scripts\activate

ğŸ“¦ Step 3 â€” Install Backend Dependencies
pip install -r requirements.txt

requirements.txt (recommended content)
fastapi==0.115.0
uvicorn==0.30.0
groq==0.12.0
sentence-transformers==2.6.0
langchain==0.2.x
langchain-community==0.2.x
pydantic==2.12.0
pydantic-settings==2.2.1
faiss-cpu==1.8.0
python-dotenv==1.0.1
PyPDF2==3.0.1
requests
streamlit

ğŸ”‘ Step 4 â€” Add Your .env File (IMPORTANT)

Location:

backend/.env


Content:

GROQ_API_KEY=your_api_key_here
EMBEDDING_MODEL=sentence-transformers/all-mpnet-base-v2

ğŸ“š Step 5 â€” Ingest Your PDF
python app/ingest.py


This builds FAISS vectorstores for pipelines A/B/C/D.

â–¶ Step 6 â€” Run Backend API Server
uvicorn app.server:app --reload


API will be available at:

http://127.0.0.1:8000/docs

ğŸ–¥ Step 7 â€” Run Streamlit Frontend

Open a second terminal:

cd frontend
streamlit run app.py


UI opens automatically at:

http://localhost:8501/

ğŸš€ Usage Flow

Upload or ingest your PDF

Ask a question

All 4 pipelines run in parallel

LLaMA evaluates them

UI shows:

ğŸ† Best Pipeline: C


Expand retrieved docs to debug retrieval quality

This is a full RAG research system.

ğŸ“¸ Screenshots (Add later)
/assets/ui.png
/assets/pipelines.png
/assets/judge.png

ğŸ§© Tech Stack

Groq LLaMA models

FAISS CPU / ChromaDB

LangChain

Sentence Transformers

FastAPI

Streamlit

â¤ï¸ Contributing

PRs welcome â€” especially:

Additional pipelines

Reranking techniques

Scoring visualizations

Long-context support

â­ Final Notes

This project is extremely useful for:

Evaluating RAG strategies

Comparing chunk sizes

Testing LLM models

Debugging retrieval quality

Choosing best RAG settings for production